{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb \n",
    "(train_data, train_labels),(test_data, test_labels) = imdb.load_data( num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jcwil\\anaconda3\\envs\\xgb\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.7743 - loss: 0.5267 - val_acc: 0.8641 - val_loss: 0.3935\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8964 - loss: 0.3135 - val_acc: 0.8815 - val_loss: 0.3131\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9219 - loss: 0.2343 - val_acc: 0.8904 - val_loss: 0.2812\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9389 - loss: 0.1873 - val_acc: 0.8881 - val_loss: 0.2757\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9478 - loss: 0.1570 - val_acc: 0.8872 - val_loss: 0.2784\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9564 - loss: 0.1333 - val_acc: 0.8807 - val_loss: 0.3121\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9676 - loss: 0.1103 - val_acc: 0.8847 - val_loss: 0.3006\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9685 - loss: 0.0990 - val_acc: 0.8850 - val_loss: 0.3149\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9774 - loss: 0.0811 - val_acc: 0.8814 - val_loss: 0.3308\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9823 - loss: 0.0691 - val_acc: 0.8784 - val_loss: 0.3703\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9863 - loss: 0.0592 - val_acc: 0.8781 - val_loss: 0.3748\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9881 - loss: 0.0508 - val_acc: 0.8786 - val_loss: 0.3881\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9903 - loss: 0.0438 - val_acc: 0.8771 - val_loss: 0.4191\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9944 - loss: 0.0330 - val_acc: 0.8654 - val_loss: 0.4884\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9967 - loss: 0.0261 - val_acc: 0.8625 - val_loss: 0.5240\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9958 - loss: 0.0251 - val_acc: 0.8732 - val_loss: 0.4846\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9956 - loss: 0.0226 - val_acc: 0.8728 - val_loss: 0.5071\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9988 - loss: 0.0147 - val_acc: 0.8727 - val_loss: 0.5287\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9973 - loss: 0.0154 - val_acc: 0.8706 - val_loss: 0.5527\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9978 - loss: 0.0130 - val_acc: 0.8709 - val_loss: 0.5757\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acc', 'loss', 'val_acc', 'val_loss'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc_values = history_dict['acc']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.7905 - loss: 0.5288 - val_acc: 0.8475 - val_loss: 0.4276\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8890 - loss: 0.3573 - val_acc: 0.8760 - val_loss: 0.3441\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9098 - loss: 0.2841 - val_acc: 0.8804 - val_loss: 0.3156\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9207 - loss: 0.2418 - val_acc: 0.8855 - val_loss: 0.2914\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9351 - loss: 0.2095 - val_acc: 0.8785 - val_loss: 0.2947\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9393 - loss: 0.1877 - val_acc: 0.8874 - val_loss: 0.2812\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9477 - loss: 0.1682 - val_acc: 0.8878 - val_loss: 0.2762\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9539 - loss: 0.1525 - val_acc: 0.8861 - val_loss: 0.2775\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9569 - loss: 0.1399 - val_acc: 0.8854 - val_loss: 0.2867\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9627 - loss: 0.1278 - val_acc: 0.8817 - val_loss: 0.2930\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9675 - loss: 0.1176 - val_acc: 0.8859 - val_loss: 0.2909\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9692 - loss: 0.1095 - val_acc: 0.8789 - val_loss: 0.3048\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9743 - loss: 0.1001 - val_acc: 0.8834 - val_loss: 0.3034\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9760 - loss: 0.0927 - val_acc: 0.8833 - val_loss: 0.3100\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9789 - loss: 0.0858 - val_acc: 0.8819 - val_loss: 0.3197\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9818 - loss: 0.0782 - val_acc: 0.8816 - val_loss: 0.3372\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9826 - loss: 0.0742 - val_acc: 0.8738 - val_loss: 0.3451\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9860 - loss: 0.0672 - val_acc: 0.8777 - val_loss: 0.3609\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9881 - loss: 0.0622 - val_acc: 0.8783 - val_loss: 0.3550\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9897 - loss: 0.0575 - val_acc: 0.8761 - val_loss: 0.3668\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - acc: 0.8673 - loss: 0.3885\n",
      "1-layer model test accuracy: 0.8672800064086914\n"
     ]
    }
   ],
   "source": [
    "# 1 hidden layer of 16 units\n",
    "model_1layer = models.Sequential()\n",
    "model_1layer.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_1layer.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1layer.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['acc'])\n",
    "\n",
    "history_1layer = model_1layer.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_1, test_acc_1 = model_1layer.evaluate(x_test, y_test)\n",
    "print(\"1-layer model test accuracy:\", test_acc_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.7665 - loss: 0.5588 - val_acc: 0.8362 - val_loss: 0.4424\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8896 - loss: 0.3468 - val_acc: 0.8760 - val_loss: 0.3286\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9138 - loss: 0.2539 - val_acc: 0.8599 - val_loss: 0.3345\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9311 - loss: 0.2005 - val_acc: 0.8911 - val_loss: 0.2741\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9443 - loss: 0.1646 - val_acc: 0.8863 - val_loss: 0.2830\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9548 - loss: 0.1387 - val_acc: 0.8868 - val_loss: 0.2885\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9616 - loss: 0.1181 - val_acc: 0.8846 - val_loss: 0.3110\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9703 - loss: 0.0967 - val_acc: 0.8816 - val_loss: 0.3225\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9720 - loss: 0.0879 - val_acc: 0.8781 - val_loss: 0.3424\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9795 - loss: 0.0687 - val_acc: 0.8791 - val_loss: 0.3628\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9844 - loss: 0.0588 - val_acc: 0.8797 - val_loss: 0.3940\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9877 - loss: 0.0466 - val_acc: 0.8716 - val_loss: 0.4259\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9906 - loss: 0.0399 - val_acc: 0.8750 - val_loss: 0.4559\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9906 - loss: 0.0350 - val_acc: 0.8744 - val_loss: 0.4746\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9943 - loss: 0.0253 - val_acc: 0.8720 - val_loss: 0.5043\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9931 - loss: 0.0253 - val_acc: 0.8716 - val_loss: 0.5323\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9981 - loss: 0.0148 - val_acc: 0.8502 - val_loss: 0.7674\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9982 - loss: 0.0116 - val_acc: 0.8698 - val_loss: 0.5912\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9960 - loss: 0.0164 - val_acc: 0.8698 - val_loss: 0.6115\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9983 - loss: 0.0095 - val_acc: 0.8497 - val_loss: 0.7488\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - acc: 0.8368 - loss: 0.8254\n",
      "3-layer model test accuracy: 0.8367999792098999\n"
     ]
    }
   ],
   "source": [
    "# 3 hidden layers of 16 units each\n",
    "model_3layer = models.Sequential()\n",
    "model_3layer.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_3layer.add(layers.Dense(16, activation='relu'))\n",
    "model_3layer.add(layers.Dense(16, activation='relu'))\n",
    "model_3layer.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3layer.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['acc'])\n",
    "\n",
    "history_3layer = model_3layer.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_3, test_acc_3 = model_3layer.evaluate(x_test, y_test)\n",
    "print(\"3-layer model test accuracy:\", test_acc_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.7707 - loss: 0.5017 - val_acc: 0.8686 - val_loss: 0.3604\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8939 - loss: 0.3013 - val_acc: 0.8856 - val_loss: 0.2942\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9234 - loss: 0.2170 - val_acc: 0.8886 - val_loss: 0.2752\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9353 - loss: 0.1827 - val_acc: 0.8883 - val_loss: 0.2789\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9484 - loss: 0.1516 - val_acc: 0.8632 - val_loss: 0.3563\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9587 - loss: 0.1260 - val_acc: 0.8727 - val_loss: 0.3312\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9584 - loss: 0.1208 - val_acc: 0.8813 - val_loss: 0.3124\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9717 - loss: 0.0900 - val_acc: 0.8798 - val_loss: 0.3311\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9791 - loss: 0.0746 - val_acc: 0.8783 - val_loss: 0.3513\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9800 - loss: 0.0686 - val_acc: 0.8787 - val_loss: 0.3713\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9861 - loss: 0.0541 - val_acc: 0.8766 - val_loss: 0.4060\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9859 - loss: 0.0493 - val_acc: 0.8665 - val_loss: 0.4558\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9892 - loss: 0.0412 - val_acc: 0.8759 - val_loss: 0.4437\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9901 - loss: 0.0369 - val_acc: 0.8741 - val_loss: 0.4635\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9962 - loss: 0.0235 - val_acc: 0.8730 - val_loss: 0.4933\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9911 - loss: 0.0304 - val_acc: 0.8730 - val_loss: 0.5140\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9969 - loss: 0.0168 - val_acc: 0.8721 - val_loss: 0.5355\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9983 - loss: 0.0124 - val_acc: 0.8670 - val_loss: 0.5959\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9995 - loss: 0.0085 - val_acc: 0.8707 - val_loss: 0.5850\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9935 - loss: 0.0217 - val_acc: 0.8704 - val_loss: 0.6074\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - acc: 0.8589 - loss: 0.6555\n",
      "32-unit model test accuracy: 0.8589199781417847\n"
     ]
    }
   ],
   "source": [
    "model_32 = models.Sequential()\n",
    "model_32.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model_32.add(layers.Dense(32, activation='relu'))\n",
    "model_32.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_32.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])\n",
    "\n",
    "history_32 = model_32.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_32, test_acc_32 = model_32.evaluate(x_test, y_test)\n",
    "print(\"32-unit model test accuracy:\", test_acc_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.7509 - loss: 0.5219 - val_acc: 0.8660 - val_loss: 0.3646\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.8836 - loss: 0.3076 - val_acc: 0.8847 - val_loss: 0.2918\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9219 - loss: 0.2171 - val_acc: 0.8376 - val_loss: 0.3903\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9281 - loss: 0.1895 - val_acc: 0.8828 - val_loss: 0.2854\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9443 - loss: 0.1509 - val_acc: 0.8462 - val_loss: 0.4025\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9543 - loss: 0.1274 - val_acc: 0.8742 - val_loss: 0.3303\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9601 - loss: 0.1115 - val_acc: 0.8820 - val_loss: 0.3174\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9749 - loss: 0.0810 - val_acc: 0.8781 - val_loss: 0.3436\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9807 - loss: 0.0652 - val_acc: 0.8504 - val_loss: 0.4823\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9781 - loss: 0.0678 - val_acc: 0.8740 - val_loss: 0.3839\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9943 - loss: 0.0298 - val_acc: 0.8688 - val_loss: 0.4393\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9895 - loss: 0.0355 - val_acc: 0.8743 - val_loss: 0.4409\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9917 - loss: 0.0306 - val_acc: 0.8765 - val_loss: 0.4596\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9889 - loss: 0.0347 - val_acc: 0.8740 - val_loss: 0.4703\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9997 - loss: 0.0084 - val_acc: 0.8723 - val_loss: 0.5145\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9907 - loss: 0.0290 - val_acc: 0.8749 - val_loss: 0.5205\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9999 - loss: 0.0046 - val_acc: 0.8769 - val_loss: 0.5558\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9889 - loss: 0.0325 - val_acc: 0.8739 - val_loss: 0.5551\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9999 - loss: 0.0031 - val_acc: 0.8731 - val_loss: 0.5888\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9999 - loss: 0.0024 - val_acc: 0.8739 - val_loss: 0.6224\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - acc: 0.8637 - loss: 0.6755\n",
      "64-unit model test accuracy: 0.8637199997901917\n"
     ]
    }
   ],
   "source": [
    "model_64 = models.Sequential()\n",
    "model_64.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model_64.add(layers.Dense(64, activation='relu'))\n",
    "model_64.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_64.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])\n",
    "\n",
    "history_64 = model_64.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_64, test_acc_64 = model_64.evaluate(x_test, y_test)\n",
    "print(\"64-unit model test accuracy:\", test_acc_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jcwil\\anaconda3\\envs\\xgb\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - acc: 0.7568 - loss: 0.5135 - val_acc: 0.8721 - val_loss: 0.3336\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.8819 - loss: 0.2990 - val_acc: 0.8573 - val_loss: 0.3460\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9115 - loss: 0.2263 - val_acc: 0.8866 - val_loss: 0.2769\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9276 - loss: 0.1862 - val_acc: 0.8850 - val_loss: 0.2811\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9493 - loss: 0.1415 - val_acc: 0.8881 - val_loss: 0.2827\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9555 - loss: 0.1199 - val_acc: 0.8851 - val_loss: 0.3052\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9743 - loss: 0.0797 - val_acc: 0.8644 - val_loss: 0.3906\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9745 - loss: 0.0793 - val_acc: 0.8843 - val_loss: 0.3553\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9821 - loss: 0.0555 - val_acc: 0.8819 - val_loss: 0.3767\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9854 - loss: 0.0488 - val_acc: 0.8823 - val_loss: 0.3884\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9989 - loss: 0.0117 - val_acc: 0.8698 - val_loss: 0.4839\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9873 - loss: 0.0461 - val_acc: 0.8799 - val_loss: 0.4584\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9963 - loss: 0.0154 - val_acc: 0.8355 - val_loss: 0.6911\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9981 - loss: 0.0084 - val_acc: 0.8774 - val_loss: 0.5111\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 0.0026 - val_acc: 0.8573 - val_loss: 0.6804\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9873 - loss: 0.0472 - val_acc: 0.8755 - val_loss: 0.5165\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 0.0019 - val_acc: 0.8751 - val_loss: 0.5716\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9886 - loss: 0.0408 - val_acc: 0.8800 - val_loss: 0.5254\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 0.0018 - val_acc: 0.8777 - val_loss: 0.5682\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 0.0010 - val_acc: 0.8772 - val_loss: 0.6206\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8686 - loss: 0.6669  \n",
      "128-unit model test accuracy: 0.8686400055885315\n"
     ]
    }
   ],
   "source": [
    "model_128 = models.Sequential()\n",
    "model_128.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model_128.add(layers.Dense(128, activation='relu'))\n",
    "model_128.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_128.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])\n",
    "\n",
    "history_128 = model_128.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_128, test_acc_128 = model_128.evaluate(x_test, y_test)\n",
    "print(\"128-unit model test accuracy:\", test_acc_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jcwil\\anaconda3\\envs\\xgb\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - acc: 0.7458 - loss: 0.5267 - val_acc: 0.7101 - val_loss: 0.6050\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.8655 - loss: 0.3208 - val_acc: 0.8607 - val_loss: 0.3258\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9062 - loss: 0.2363 - val_acc: 0.8822 - val_loss: 0.2841\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9283 - loss: 0.1889 - val_acc: 0.8781 - val_loss: 0.2973\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9499 - loss: 0.1379 - val_acc: 0.8196 - val_loss: 0.4849\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9655 - loss: 0.0983 - val_acc: 0.7981 - val_loss: 0.6363\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9665 - loss: 0.0953 - val_acc: 0.8821 - val_loss: 0.3136\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9782 - loss: 0.0714 - val_acc: 0.8829 - val_loss: 0.3324\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9843 - loss: 0.0507 - val_acc: 0.8811 - val_loss: 0.3313\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9990 - loss: 0.0123 - val_acc: 0.8834 - val_loss: 0.4371\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9833 - loss: 0.0637 - val_acc: 0.8828 - val_loss: 0.3907\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9998 - loss: 0.0049 - val_acc: 0.8837 - val_loss: 0.4805\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - acc: 0.9999 - loss: 0.0029 - val_acc: 0.7691 - val_loss: 1.4908\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9837 - loss: 0.0764 - val_acc: 0.8828 - val_loss: 0.4675\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 1.0000 - loss: 0.0019 - val_acc: 0.8821 - val_loss: 0.5395\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 1.0000 - loss: 0.0011 - val_acc: 0.8545 - val_loss: 0.8331\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9839 - loss: 0.0731 - val_acc: 0.8809 - val_loss: 0.5004\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 1.0000 - loss: 0.0012 - val_acc: 0.8811 - val_loss: 0.5666\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 1.0000 - loss: 6.7950e-04 - val_acc: 0.8789 - val_loss: 0.6179\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 1.0000 - loss: 4.4425e-04 - val_acc: 0.8815 - val_loss: 0.6507\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8722 - loss: 0.6963\n",
      "256-unit model test accuracy: 0.872160017490387\n"
     ]
    }
   ],
   "source": [
    "model_256 = models.Sequential()\n",
    "model_256.add(layers.Dense(256, activation='relu', input_shape=(10000,)))\n",
    "model_256.add(layers.Dense(256, activation='relu'))\n",
    "model_256.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_256.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])\n",
    "\n",
    "history_256 = model_256.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_256, test_acc_256 = model_256.evaluate(x_test, y_test)\n",
    "print(\"256-unit model test accuracy:\", test_acc_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jcwil\\anaconda3\\envs\\xgb\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7346 - loss: 0.1974 - val_acc: 0.8568 - val_loss: 0.1507\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8855 - loss: 0.1169 - val_acc: 0.8808 - val_loss: 0.1073\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9121 - loss: 0.0846 - val_acc: 0.8843 - val_loss: 0.0937\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9281 - loss: 0.0675 - val_acc: 0.8888 - val_loss: 0.0868\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9410 - loss: 0.0560 - val_acc: 0.8884 - val_loss: 0.0847\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9520 - loss: 0.0471 - val_acc: 0.8794 - val_loss: 0.0873\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9557 - loss: 0.0429 - val_acc: 0.8802 - val_loss: 0.0890\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9617 - loss: 0.0376 - val_acc: 0.8802 - val_loss: 0.0863\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9685 - loss: 0.0326 - val_acc: 0.8809 - val_loss: 0.0862\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9746 - loss: 0.0284 - val_acc: 0.8809 - val_loss: 0.0870\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9741 - loss: 0.0274 - val_acc: 0.8796 - val_loss: 0.0879\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9792 - loss: 0.0232 - val_acc: 0.8773 - val_loss: 0.0897\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9825 - loss: 0.0216 - val_acc: 0.8736 - val_loss: 0.0934\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9857 - loss: 0.0185 - val_acc: 0.8763 - val_loss: 0.0923\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9854 - loss: 0.0174 - val_acc: 0.8751 - val_loss: 0.0933\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9876 - loss: 0.0161 - val_acc: 0.8637 - val_loss: 0.1046\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9876 - loss: 0.0152 - val_acc: 0.8733 - val_loss: 0.0960\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9893 - loss: 0.0136 - val_acc: 0.8737 - val_loss: 0.0963\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9902 - loss: 0.0126 - val_acc: 0.8727 - val_loss: 0.0973\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 0.9926 - loss: 0.0104 - val_acc: 0.8707 - val_loss: 0.0992\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8633 - loss: 0.1065\n",
      "MSE loss model test accuracy: 0.8632799983024597\n"
     ]
    }
   ],
   "source": [
    "# Baseline architecture but with MSE loss\n",
    "model_mse = models.Sequential()\n",
    "model_mse.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model_mse.add(layers.Dense(16, activation='relu'))\n",
    "model_mse.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mse.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "history_mse = model_mse.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_mse, test_acc_mse = model_mse.evaluate(x_test, y_test)\n",
    "print(\"MSE loss model test accuracy:\", test_acc_mse) #better than baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jcwil\\anaconda3\\envs\\xgb\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7870 - loss: 0.4916 - val_acc: 0.8576 - val_loss: 0.3741\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8999 - loss: 0.2906 - val_acc: 0.8791 - val_loss: 0.3023\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9226 - loss: 0.2150 - val_acc: 0.8792 - val_loss: 0.2947\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9415 - loss: 0.1693 - val_acc: 0.8892 - val_loss: 0.2740\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9567 - loss: 0.1318 - val_acc: 0.8594 - val_loss: 0.3665\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9621 - loss: 0.1126 - val_acc: 0.8821 - val_loss: 0.3148\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9694 - loss: 0.0925 - val_acc: 0.8744 - val_loss: 0.3530\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9757 - loss: 0.0755 - val_acc: 0.8684 - val_loss: 0.3929\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9806 - loss: 0.0604 - val_acc: 0.8740 - val_loss: 0.4153\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9870 - loss: 0.0474 - val_acc: 0.8729 - val_loss: 0.4585\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9879 - loss: 0.0423 - val_acc: 0.8722 - val_loss: 0.4728\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9878 - loss: 0.0376 - val_acc: 0.8698 - val_loss: 0.5193\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9909 - loss: 0.0316 - val_acc: 0.8688 - val_loss: 0.5371\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9901 - loss: 0.0327 - val_acc: 0.8535 - val_loss: 0.6280\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9987 - loss: 0.0114 - val_acc: 0.8638 - val_loss: 0.5940\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9922 - loss: 0.0294 - val_acc: 0.8676 - val_loss: 0.6080\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9965 - loss: 0.0144 - val_acc: 0.8590 - val_loss: 0.6576\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9997 - loss: 0.0057 - val_acc: 0.8661 - val_loss: 0.6575\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9929 - loss: 0.0294 - val_acc: 0.8646 - val_loss: 0.6776\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9998 - loss: 0.0032 - val_acc: 0.8663 - val_loss: 0.6876\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - acc: 0.8510 - loss: 0.7564\n",
      "tanh model test accuracy: 0.8510400056838989\n"
     ]
    }
   ],
   "source": [
    "# tanh\n",
    "model_tanh = models.Sequential()\n",
    "model_tanh.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model_tanh.add(layers.Dense(16, activation='tanh'))\n",
    "model_tanh.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_tanh.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['acc'])\n",
    "\n",
    "history_tanh = model_tanh.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_tanh, test_acc_tanh = model_tanh.evaluate(x_test, y_test)\n",
    "print(\"tanh model test accuracy:\", test_acc_tanh) #slightly worse than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - acc: 0.7126 - loss: 0.1910 - val_acc: 0.7607 - val_loss: 0.1625\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.8615 - loss: 0.1047 - val_acc: 0.7849 - val_loss: 0.1515\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.8904 - loss: 0.0833 - val_acc: 0.8779 - val_loss: 0.0898\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9121 - loss: 0.0673 - val_acc: 0.8759 - val_loss: 0.0908\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9227 - loss: 0.0586 - val_acc: 0.8743 - val_loss: 0.0914\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9353 - loss: 0.0505 - val_acc: 0.8839 - val_loss: 0.0838\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9490 - loss: 0.0420 - val_acc: 0.8827 - val_loss: 0.0847\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.9551 - loss: 0.0365 - val_acc: 0.8833 - val_loss: 0.0856\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9644 - loss: 0.0303 - val_acc: 0.8717 - val_loss: 0.0943\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9718 - loss: 0.0254 - val_acc: 0.8797 - val_loss: 0.0880\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9757 - loss: 0.0218 - val_acc: 0.8817 - val_loss: 0.0893\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9791 - loss: 0.0189 - val_acc: 0.8807 - val_loss: 0.0889\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9796 - loss: 0.0178 - val_acc: 0.8830 - val_loss: 0.0895\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9928 - loss: 0.0080 - val_acc: 0.8747 - val_loss: 0.0989\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.9800 - loss: 0.0171 - val_acc: 0.8809 - val_loss: 0.0923\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9945 - loss: 0.0061 - val_acc: 0.8791 - val_loss: 0.0972\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9790 - loss: 0.0172 - val_acc: 0.8788 - val_loss: 0.0930\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9951 - loss: 0.0054 - val_acc: 0.8794 - val_loss: 0.0957\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9952 - loss: 0.0051 - val_acc: 0.8798 - val_loss: 0.0963\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9831 - loss: 0.0146 - val_acc: 0.8821 - val_loss: 0.0947\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8749 - loss: 0.1004\n",
      "MSE loss + 256 model test accuracy: 0.8749200105667114\n"
     ]
    }
   ],
   "source": [
    "# Baseline architecture but with MSE loss and 256 units\n",
    "model_mse = models.Sequential()\n",
    "model_mse.add(layers.Dense(256, activation='relu', input_shape=(10000,)))\n",
    "model_mse.add(layers.Dense(256, activation='relu'))\n",
    "model_mse.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mse.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "history_mse = model_mse.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_mse, test_acc_mse = model_mse.evaluate(x_test, y_test)\n",
    "print(\"MSE loss + 256 model test accuracy:\", test_acc_mse) #better than baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - acc: 0.7001 - loss: 0.2011 - val_acc: 0.8417 - val_loss: 0.1226\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.8589 - loss: 0.1045 - val_acc: 0.8070 - val_loss: 0.1391\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.8932 - loss: 0.0800 - val_acc: 0.8815 - val_loss: 0.0874\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9139 - loss: 0.0656 - val_acc: 0.8681 - val_loss: 0.0961\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9318 - loss: 0.0532 - val_acc: 0.8722 - val_loss: 0.0949\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9471 - loss: 0.0414 - val_acc: 0.8736 - val_loss: 0.0955\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9603 - loss: 0.0330 - val_acc: 0.8462 - val_loss: 0.1218\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9650 - loss: 0.0302 - val_acc: 0.8816 - val_loss: 0.0908\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - acc: 0.9697 - loss: 0.0251 - val_acc: 0.8812 - val_loss: 0.0914\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - acc: 0.9901 - loss: 0.0100 - val_acc: 0.8787 - val_loss: 0.0954\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9793 - loss: 0.0191 - val_acc: 0.8809 - val_loss: 0.0955\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - acc: 0.9927 - loss: 0.0073 - val_acc: 0.8714 - val_loss: 0.1058\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9768 - loss: 0.0200 - val_acc: 0.8799 - val_loss: 0.0983\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9938 - loss: 0.0063 - val_acc: 0.8813 - val_loss: 0.0980\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9814 - loss: 0.0162 - val_acc: 0.8809 - val_loss: 0.0961\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9944 - loss: 0.0056 - val_acc: 0.8815 - val_loss: 0.0972\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9950 - loss: 0.0051 - val_acc: 0.8667 - val_loss: 0.1110\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9813 - loss: 0.0169 - val_acc: 0.8796 - val_loss: 0.0985\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9952 - loss: 0.0048 - val_acc: 0.8792 - val_loss: 0.1006\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9953 - loss: 0.0047 - val_acc: 0.8790 - val_loss: 0.1011\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8736 - loss: 0.1065\n",
      "MSE loss + 256 + 3 layers model test accuracy: 0.8736000061035156\n"
     ]
    }
   ],
   "source": [
    "# Baseline architecture but with MSE loss and 256 units and 3 layers\n",
    "model_mse = models.Sequential()\n",
    "model_mse.add(layers.Dense(256, activation='relu', input_shape=(10000,)))\n",
    "model_mse.add(layers.Dense(256, activation='relu'))\n",
    "model_mse.add(layers.Dense(256, activation='relu'))\n",
    "model_mse.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mse.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "history_mse = model_mse.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "test_loss_mse, test_acc_mse = model_mse.evaluate(x_test, y_test)\n",
    "print(\"MSE loss + 256 + 3 layers model test accuracy:\", test_acc_mse) #better than baseline\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
